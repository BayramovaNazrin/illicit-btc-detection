{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BayramovaNazrin/illicit-btc-detection/blob/main/graphsage_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Data**"
      ],
      "metadata": {
        "id": "im5GPD6REFdb"
      },
      "id": "im5GPD6REFdb"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/BayramovaNazrin/illicit-btc-detection.git\n",
        "%cd /content/illicit-btc-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aczJkksD6G7",
        "outputId": "adafcf85-b16d-4503-c7a4-5e29650cf2bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'illicit-btc-detection'...\n",
            "remote: Enumerating objects: 196, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 196 (delta 26), reused 14 (delta 14), pack-reused 158 (from 1)\u001b[K\n",
            "Receiving objects: 100% (196/196), 6.82 MiB | 23.13 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n",
            "/content/illicit-btc-detection\n"
          ]
        }
      ],
      "id": "7aczJkksD6G7"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/illicit-btc-detection')\n",
        "\n",
        "from load_data import load_data\n",
        "features, edges, classes, merged_df = load_data()"
      ],
      "metadata": {
        "id": "zC1tYBawEKQR"
      },
      "execution_count": 4,
      "outputs": [],
      "id": "zC1tYBawEKQR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports**"
      ],
      "metadata": {
        "id": "MFljflbWEa-p"
      },
      "id": "MFljflbWEa-p"
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch\n",
        "\n",
        "# Remove any old or incompatible builds\n",
        "!pip uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv > /dev/null\n",
        "\n",
        "# Install supported versions (PyTorch 2.5 + cu121)\n",
        "!pip install -q torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Install matching PyTorch Geometric wheels\n",
        "!pip install -q torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
        "    -f https://data.pyg.org/whl/torch-2.5.0+cu121.html\n",
        "\n",
        "# Verify installation\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"PyG origin:\", torch_geometric.__file__)\n",
        "print(\"SAGEConv import OK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRHMG4MUWrjP",
        "outputId": "fb48cbcd-12cf-428d-b391-3b81fc9e0151"
      },
      "id": "VRHMG4MUWrjP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m601.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m994.8/994.8 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTorch: 2.5.0+cu121\n",
            "PyG origin: /usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py\n",
            "SAGEConv import OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d0b492e",
      "metadata": {
        "id": "5d0b492e"
      },
      "outputs": [],
      "source": [
        "import os, torch\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, precision_score, recall_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e36cd10",
      "metadata": {
        "id": "9e36cd10"
      },
      "source": [
        "# **Data Loading and Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf52412b",
      "metadata": {
        "id": "bf52412b"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_data(features_path, edges_path, classes_path):\n",
        "    print(\"Loading data...\")\n",
        "    features_df = pd.read_csv(features_path).fillna(0)\n",
        "    edges_df = pd.read_csv(edges_path)\n",
        "    classes_df = pd.read_csv(classes_path)\n",
        "\n",
        "    # Map textual labels to numeric\n",
        "    classes_df['class'] = classes_df['class'].map({'unknown': 3, '1': 1, '2': 2})\n",
        "    return features_df, edges_df, classes_df\n",
        "\n",
        "def preprocess_and_create_graph(features_df, edges_df, classes_df):\n",
        "    print(\"Preprocessing and constructing graph...\")\n",
        "\n",
        "    combined_df = pd.merge(features_df, classes_df, on='txId', how='inner')\n",
        "    labeled_df = combined_df[combined_df['class'].isin([1, 2])].copy()\n",
        "    labeled_df['class'] = labeled_df['class'].map({1: 1, 2: 0})\n",
        "    labeled_df = labeled_df.sort_values('txId').reset_index(drop=True)\n",
        "\n",
        "    txid_map = {txid: i for i, txid in enumerate(labeled_df['txId'])}\n",
        "    feature_cols = labeled_df.columns.drop(['txId', 'Time step', 'class'])\n",
        "    node_features = labeled_df[feature_cols].values\n",
        "    scaler = StandardScaler()\n",
        "    node_features_scaled = scaler.fit_transform(node_features)\n",
        "    x = torch.tensor(node_features_scaled, dtype=torch.float)\n",
        "\n",
        "    valid_edges = edges_df[edges_df['txId1'].isin(txid_map) & edges_df['txId2'].isin(txid_map)].copy()\n",
        "    valid_edges['txId1_idx'] = valid_edges['txId1'].map(txid_map)\n",
        "    valid_edges['txId2_idx'] = valid_edges['txId2'].map(txid_map)\n",
        "    edge_index = torch.tensor(valid_edges[['txId1_idx', 'txId2_idx']].values.T, dtype=torch.long)\n",
        "\n",
        "    y = torch.tensor(labeled_df['class'].values, dtype=torch.long)\n",
        "\n",
        "    time_steps = torch.tensor(labeled_df['Time step'].values)\n",
        "    train_mask = (time_steps <= 34)\n",
        "    test_mask = (time_steps > 34)\n",
        "\n",
        "    graph_data = Data(x=x, edge_index=edge_index, y=y)\n",
        "    graph_data.train_mask = train_mask\n",
        "    graph_data.test_mask = test_mask\n",
        "\n",
        "    print(\"\\nGraph construction complete:\")\n",
        "    print(f\"  - Nodes: {graph_data.num_nodes:,}\")\n",
        "    print(f\"  - Edges: {graph_data.num_edges:,}\")\n",
        "    print(f\"  - Labeled for Training: {graph_data.train_mask.sum():,}\")\n",
        "    print(f\"  - Labeled for Testing: {graph_data.test_mask.sum():,}\\n\")\n",
        "\n",
        "    return graph_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f09f910",
      "metadata": {
        "id": "9f09f910"
      },
      "source": [
        "# **Model Definition: GraphSAGE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "700b0c9b",
      "metadata": {
        "id": "700b0c9b"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GraphSAGEModel(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GraphSAGEModel, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd59eb42",
      "metadata": {
        "id": "cd59eb42"
      },
      "source": [
        "# **Training and Evaluation Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15c57105",
      "metadata": {
        "id": "15c57105"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(model, data, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, data):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred_probs = F.softmax(out, dim=1)\n",
        "    preds = pred_probs.argmax(dim=1)\n",
        "\n",
        "    test_preds = preds[data.test_mask].cpu().numpy()\n",
        "    test_labels = data.y[data.test_mask].cpu().numpy()\n",
        "    test_probs = pred_probs[data.test_mask][:, 1].cpu().numpy()\n",
        "\n",
        "    accuracy = accuracy_score(test_labels, test_preds)\n",
        "    f1 = f1_score(test_labels, test_preds, average='binary')\n",
        "    precision = precision_score(test_labels, test_preds, average='binary')\n",
        "    recall = recall_score(test_labels, test_preds, average='binary')\n",
        "    roc_auc = roc_auc_score(test_labels, test_probs)\n",
        "    pr_auc = average_precision_score(test_labels, test_probs)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1_score\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ba5e9ba",
      "metadata": {
        "id": "8ba5e9ba"
      },
      "source": [
        "# **Main Training Execution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "399d8a80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "399d8a80",
        "outputId": "fbde6281-6387-4c32-9648-7254d410872f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Preprocessing and constructing graph...\n",
            "\n",
            "Graph construction complete:\n",
            "  - Nodes: 46,564\n",
            "  - Edges: 36,624\n",
            "  - Labeled for Training: 29,894\n",
            "  - Labeled for Testing: 16,670\n",
            "\n",
            "Using device: cpu\n",
            "\n",
            "Starting training...\n",
            "Epoch: 010, Loss: 0.1971, Test Accuracy: 0.9423, Test F1: 0.5458\n",
            "Epoch: 020, Loss: 0.1513, Test Accuracy: 0.9422, Test F1: 0.5665\n",
            "Epoch: 030, Loss: 0.1174, Test Accuracy: 0.9425, Test F1: 0.5565\n",
            "Epoch: 040, Loss: 0.0981, Test Accuracy: 0.9443, Test F1: 0.5664\n",
            "Epoch: 050, Loss: 0.0862, Test Accuracy: 0.9458, Test F1: 0.5784\n",
            "Epoch: 060, Loss: 0.0772, Test Accuracy: 0.9493, Test F1: 0.6006\n",
            "Epoch: 070, Loss: 0.0727, Test Accuracy: 0.9536, Test F1: 0.6242\n",
            "Epoch: 080, Loss: 0.0696, Test Accuracy: 0.9564, Test F1: 0.6403\n",
            "Epoch: 090, Loss: 0.0651, Test Accuracy: 0.9581, Test F1: 0.6442\n",
            "Epoch: 100, Loss: 0.0641, Test Accuracy: 0.9647, Test F1: 0.6849\n",
            "Epoch: 110, Loss: 0.0616, Test Accuracy: 0.9645, Test F1: 0.6838\n",
            "Epoch: 120, Loss: 0.0588, Test Accuracy: 0.9638, Test F1: 0.6804\n",
            "Epoch: 130, Loss: 0.0573, Test Accuracy: 0.9605, Test F1: 0.6559\n",
            "Epoch: 140, Loss: 0.0556, Test Accuracy: 0.9650, Test F1: 0.6840\n",
            "Epoch: 150, Loss: 0.0546, Test Accuracy: 0.9651, Test F1: 0.6851\n",
            "Epoch: 160, Loss: 0.0540, Test Accuracy: 0.9648, Test F1: 0.6798\n",
            "Epoch: 170, Loss: 0.0521, Test Accuracy: 0.9667, Test F1: 0.6982\n",
            "Epoch: 180, Loss: 0.0501, Test Accuracy: 0.9642, Test F1: 0.6806\n",
            "Epoch: 190, Loss: 0.0498, Test Accuracy: 0.9662, Test F1: 0.6894\n",
            "Epoch: 200, Loss: 0.0488, Test Accuracy: 0.9647, Test F1: 0.6790\n",
            "\n",
            "Training finished. Final evaluation:\n",
            "  - Accuracy: 0.9647\n",
            "  - F1 Score: 0.6790\n",
            "  - Precision: 0.8304\n",
            "  - Recall: 0.5743\n",
            "  - Roc Auc: 0.8957\n",
            "  - Pr Auc: 0.6515\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    features_path = '/content/drive/MyDrive/anomaly_detection/txs_features.csv'\n",
        "    edges_path = '/content/drive/MyDrive/anomaly_detection/elliptic_txs_edgelist.csv'\n",
        "    classes_path = '/content/drive/MyDrive/anomaly_detection/elliptic_txs_classes.csv'\n",
        "\n",
        "    features_df, edges_df, classes_df = load_data(features_path, edges_path, classes_path)\n",
        "    graph_data = preprocess_and_create_graph(features_df, edges_df, classes_df)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\\n\")\n",
        "    graph_data = graph_data.to(device)\n",
        "\n",
        "    num_node_features = graph_data.num_node_features\n",
        "    num_classes = 2\n",
        "    hidden_dim = 128\n",
        "\n",
        "    model = GraphSAGEModel(in_channels=num_node_features, hidden_channels=hidden_dim, out_channels=num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    epochs = 200\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        loss = train(model, graph_data, optimizer, criterion)\n",
        "        if epoch % 10 == 0:\n",
        "            metrics = test(model, graph_data)\n",
        "            print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Accuracy: {metrics['accuracy']:.4f}, Test F1: {metrics['f1_score']:.4f}\")\n",
        "\n",
        "    print(\"\\nTraining finished. Final evaluation:\")\n",
        "    final_metrics = test(model, graph_data)\n",
        "    for metric, value in final_metrics.items():\n",
        "        print(f\"  - {metric.replace('_', ' ').title()}: {value:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}